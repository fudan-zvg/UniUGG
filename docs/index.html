<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0"/>
  <title>UniUGG</title>
  <link rel="stylesheet" href="assets/style.css">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/simple-datatables@latest/dist/style.css">

  <!-- Global site tag (gtag.js) - Google Analytics -->
  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro" rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">

  <style>
  .render_wrapper {
    position: relative;
          height: 300px;
        }
      .render_wrapper_small {
    position: relative;
          height: 200px;
        }
  .render_div {
    position: absolute;
    top: 0;
    left: 0;
  }

      #interpolation-image-wrapper-car{
          text-align: center;
      }
      #interpolation-image-wrapper-chair{
          text-align: center;
      }
      .nested-columns {
          margin-bottom: 0 !important;
      }
  </style>

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>

</head>

  <body>
    <link rel="icon" type="image/png" href="./assets/icons/s_logo.png">

    <!-- <div class="top-logo-bar">üåå Spatial Perception And Reasoning</div> -->
    <!-- <div class="top-logo-bar">üåå <span class="spar-logo">
      <strong>S</strong>patial <strong>P</strong>erception <strong>A</strong>nd <strong>R</strong>easoning
    </span></div> -->
    <header class="hero-header">
    
    <!-- <img src="assets/icons/bg2.png" class="header-bg" alt="background"> -->


    <div class="hero-content">

      <!-- <h1 class="project-title">From Flatland to Space</h1> -->

      <!-- <h1 class="project-title">From Flatland to Space</h1> -->
      <div class="title-wrapper">
        <!-- <img src="assets/icons/sub_bg.jpg" alt="Title Banner" class="title-deco-img"> -->
        <h1 class="project-title">UniUGG</h1>
      </div>
      <p class="project-subtitle">Unified 3D Understanding and Generation via Geometric-Semantic Encoding</p>
      <div class="authors-list">
        <div class="author-names">
          Yueming Xu<sup>1&ast;</sup>, Jiahui Zhang<sup>1&ast;</sup>, Ze Huang<sup>1&ast;</sup>, Yurui Chen<sup>1</sup>,
          Yanpeng Zhou<sup>2</sup>, Zhenyu Chen<sup>2</sup>, Yu-Jie Yuan<sup>2</sup>,
          Pengxiang Xia<sup>2</sup>, Guowei Huang<sup>2</sup>, Xinyue Cai<sup>2</sup>, Zhongang Qi<sup>2</sup>,
          Xingyue Quan<sup>2</sup>, Jianye Hao<sup>2</sup>,
          Hang Xu<sup>2</sup>, <a href="https://lzrobots.github.io/" target="_blank">Li Zhang<sup>1&dagger;</sup></a>
        </div>
      
        <div class="equal-contribution">&ast; Equal contribution &nbsp;&nbsp; &dagger; Corresponding author</div>
      
        <div class="affiliations">
          <span class="inst"><sup>1</sup> Fudan University</span>
          <span class="inst"><sup>2</sup> Noah‚Äôs Ark Lab</span>
        </div>
      </div>
  
      <div class="button-group">
        <!-- <a href="https://fudan-zvg.github.io/UniUGG/docs/assets/UniUGG.pdf" target="_blank" class="circle-button green">
          <img src="assets/icons/paper.svg" alt="Paper" class="icon"> Paper
        </a> -->
        <a href="https://arxiv.org/abs/2508.11952" target="_blank" class="circle-button green">
          <img src="assets/icons/arxiv.svg" alt="arXiv" class="icon"> arXiv
        </a>
        <a href="https://github.com/fudan-zvg/UniUGG.git" target="_blank" class="circle-button green">
          <img src="assets/icons/github.svg" alt="Code" class="icon"> Code
        </a>
      </div>
    </div>
  </header>

    <div class="main-content-t">
      <section class="teaser-section", id="overview">
        <!-- <h2 class="teaser-title">Overview of the SPAR Dataset and Benchmark</h2> -->
        <img src="assets/images/teaser.png" alt="Teaser Figure" class="teaser-image">
        <p class="teaser-caption">
          <em>
            Overview of our <strong>UniUGG</strong>, the first unified framework for spatial understanding and generation. 
            (A) UniUGG supports spatial-level VQA and generates geometrically consistent 3D scenes. (B) Given a reference image, it can creatively
            generate 3D variations and describe them accurately. (C) UniUGG outperforms baselines in both spatial understanding and
            generation, with our specially tuned vision encoder excelling in downstream tasks.
          </em>
        </p>
    </section>
    </div>
      
    <!-- <section class="hero is-light is-small", id = "vis_gen">
        <div class="hero-body">
            <div class="container">
                 <div id="results-carousel" class="carousel results-carousel">
                    <div class="item item-steve render_wrapper">
			            <div id="sample_case1" class="render_div"></div>
                    </div>
                    <div class="item item-steve render_wrapper">
			            <div id="sample_case2" class="render_div"></div>
                    </div>
                    <div class="item item-steve render_wrapper">
			            <div id="sample_case3" class="render_div"></div>
                    </div>
                    <div class="item item-steve render_wrapper">
			            <div id="sample_case4" class="render_div"></div>
                    </div>
                    <div class="item item-steve render_wrapper">
			            <div id="sample_case5" class="render_div"></div>
                    </div>
                </div>
                <div style="text-align: center;">
                  Given a reference image and the relative view transformation, UniUGG can generate the corresponding 3D scenes.<br>
                  Here are the pointmaps of reference views. <b>Press <span style="font-size: 20px;">G</span> to see the generated scenes. Press <span style="font-size: 20px;">R</span> to reset.</b> </div>
            </div>
        </div>
    </section> -->

    <!-- section ÂºÄÂßã -->
    <section class="hero is-light is-small" id="vis_gen">
      <div class="hero-body">
        <div class="container">
          <div id="results-carousel" class="carousel results-carousel">
            <!-- Item 1 -->
            <div class="item">
              <!-- <div class="reference-image-wrapper">
                <img src="./models/sample1.png" alt="Reference View 1" class="reference-image">
              </div> -->
              <div class="reference-block">
                <img src="./models/sample1.png" alt="Reference View 1" class="reference-image">
                <div class="reference-caption">
                  View transformation:<br>
                  Shifted left‚Äìdown‚Äìbackward, pitch up 3¬∞, roll left 15¬∞.
                </div>
              </div>
              <div class="render-container">
                <div id="sample_case1" class="render_div"></div>
              </div>
            </div>

            <!-- Item 2 -->
            <div class="item">
              <div class="reference-block">
                <img src="./models/sample2.png" alt="Reference View 1" class="reference-image">
                <div class="reference-caption">
                  View transformation:<br>
                  Shifted left‚Äìbackward, yaw right 10¬∞, pitch down 8¬∞.
                </div>
              </div>
              <div class="render-container">
                <div id="sample_case2" class="render_div"></div>
              </div>
            </div>
            
            <!-- Item 3 -->
            <div class="item">
              <div class="reference-block">
                <img src="./models/sample3.png" alt="Reference View 1" class="reference-image">
                <div class="reference-caption">
                  View transformation:<br>
                  Shifted right‚Äìdown‚Äìforward, yaw left 30¬∞, pitch down 2¬∞.
                </div>
              </div>
              <div class="render-container">
                <div id="sample_case3" class="render_div"></div>
              </div>
            </div>

            <!-- Item 4 -->
            <div class="item">
              <div class="reference-block">
                <img src="./models/case1.jpg" alt="Reference View 1" class="reference-image">
                <div class="reference-caption">
                  View transformation:<br>
                  Yaw right 40¬∞.
                </div>
              </div>
              <div class="render-container">
                <div id="sample_case4" class="render_div"></div>
              </div>
            </div>

            <!-- Item 5 -->
            <div class="item">
              <div class="reference-block">
                <img src="./models/sample5.png" alt="Reference View 1" class="reference-image">
                <div class="reference-caption">
                  View transformation:<br>
                  Shifted slightly right‚Äìup‚Äìforward, yaw right 24¬∞, pitch up 2¬∞.
                </div>
              </div>
              <div class="render-container">
                <div id="sample_case5" class="render_div"></div>
              </div>
            </div>

          </div>
          <div style="text-align: center;">
          <br>
          Given a reference image and the relative view transformation, UniUGG can generate the corresponding 3D scenes.<br>
          Here are the pointmaps of reference views. <b>Press <span style="font-size: 20px;">G</span> to see the generated scenes. Press <span style="font-size: 20px;">R</span> to reset.</b> 
          </div>
        </div>
      </div>
    </section>


    <div class="main-content">
      <section class="summary-section", id="paper-summary">
        <h2 class="summary-title">üìÑ Abstract</h2>
        <p class="summary-text">
        Despite the impressive progress on understanding and generating images shown by the recent unified architectures, 
        the integration of 3D tasks remains challenging and largely unexplored. In this paper, we introduce UniUGG, the first unified understanding and generation framework for 3D modalities. Our unified framework employs an LLM to comprehend and decode sentences and 3D representations. At its core, we propose a spatial decoder leveraging a latent diffusion model to generate high-quality 3D representations. This allows for the generation and imagination of 3D scenes based on a reference image and an arbitrary view transformation, while remaining supports for spatial visual question answering (VQA) tasks. Additionally, we propose a geometric-semantic learning strategy to pretrain the vision encoder. This design jointly captures the input's semantic and geometric cues, enhancing both spatial understanding and generation. Extensive experimental results demonstrate the superiority of our method in visual representation, spatial understanding, and 3D generation.
        </p>
      </section>

      <section class="video-section", id="video">
        <h2 class="video-title">üéûÔ∏è Video</h2>
        <div class="video-box">
        <video id="demo-video" controls preload="metadata" poster="assets/cover.jpg" playsinline>
          <source src="assets/demo.mp4" type="video/mp4">
          </video>
        </div>
      </section>

      <section id="generation_comparison">
      <h2 class="task-vis-title">‚öñÔ∏è 3D generation comparison</h2>
                <p>
                    UniUGG accurately captures the input view transformation and leverages the reference image to ‚Äòimagine‚Äô fine-grained spatial structures under novel views, and outputs correct captioning.                </p>
          <section class="section-seed" style="overflow:hidden;">
                  <div id="post_images" class="carousel">
                          <div class="grid_comp">
                              <!-- Top Left: Reference Image -->
                              <div class="grid-item_comp">
                                <div class="title_comp">Reference image</div>
                                <img src="./models/case1.jpg" alt="Reference" class="image-box_comp" id="ref_img_comp">
                              </div>

                              <!-- Top Right: Yaw Render -->
                              <div class="grid-item_comp">
                                <div class="title_comp">Yaw right 40¬∞</div>
                                <div class="mesh-box-comp" id="meshcomp_cut3r1"></div>
                                <div class="model-name_comp">CUT3R</div>
                              </div>
                              <!-- Bottom Left: Caption -->
                              <div class="grid-item_comp">
                                <div class="title_comp">Caption</div>
                                <div class="caption-box_comp" id="caption_comp">
                                  A bathroom scene featuring a window with a small shelf. Below the shelf, a bathtub is partially visible. The walls are tiled, and the overall layout shows the window as the back.
                                </div>
                              </div>

                              <!-- Bottom Right: Highlighted View -->
                              <div class="grid-item_comp">
                                <div class="mesh-box-comp" id="meshcomp_ours1"></div>
                                <div class="model-name_comp"><strong>UniUGG</strong></div>
                              </div>
                            </div>
                                                      <div class="grid_comp">
                              <!-- Top Left: Reference Image -->
                              <div class="grid-item_comp">
                                <div class="title_comp">Reference image</div>
                                <img src="./models/case2.jpg" alt="Reference" class="image-box_comp" id="ref_img_comp">
                              </div>

                              <!-- Top Right: Yaw Render -->
                              <div class="grid-item_comp">
                                <div class="title_comp">Yaw right 40¬∞</div>
                                <div class="mesh-box-comp" id="meshcomp_cut3r2"></div>
                                <div class="model-name_comp">CUT3R</div>
                              </div>
                              <!-- Bottom Left: Caption -->
                              <div class="grid-item_comp">
                                <div class="title_comp">Caption</div>
                                <div class="caption-box_comp" id="caption_comp">
                                  A window with two panes is centered in the image, flanked by two frosted glass panels. On the windowsill, there is a small decorative item.
                                </div>
                              </div>

                              <!-- Bottom Right: Highlighted View -->
                              <div class="grid-item_comp">
                                <div class="mesh-box-comp" id="meshcomp_ours2"></div>
                                <div class="model-name_comp"><strong>UniUGG</strong></div>
                              </div>
                            </div>
                                                      <div class="grid_comp">
                              <!-- Top Left: Reference Image -->
                              <div class="grid-item_comp">
                                <div class="title_comp">Reference image</div>
                                <img src="./models/case3.jpg" alt="Reference" class="image-box_comp" id="ref_img_comp">
                              </div>

                              <!-- Top Right: Yaw Render -->
                              <div class="grid-item_comp">
                                <div class="title_comp">Pitch down 40¬∞, Yaw left 40¬∞</div>
                                <div class="mesh-box-comp" id="meshcomp_cut3r3"></div>
                                <div class="model-name_comp">CUT3R</div>
                              </div>
                              <!-- Bottom Left: Caption -->
                              <div class="grid-item_comp">
                                <div class="title_comp">Caption</div>
                                <div class="caption-box_comp" id="caption_comp">
                                  A gray sectional sofa is positioned to the right, with a small table in front of it holding an item. In the background, a dining area is visible.                                </div>
                              </div>

                              <!-- Bottom Right: Highlighted View -->
                              <div class="grid-item_comp">
                                <div class="mesh-box-comp" id="meshcomp_ours3"></div>
                                <div class="model-name_comp"><strong>UniUGG</strong></div>
                              </div>
                            </div>
                  </div>
        <script src="https://cdn.jsdelivr.net/npm/bulma-carousel@4.0.3/dist/js/bulma-carousel.min.js"></script>
                <script>
                    bulmaCarousel.attach('#post_images', {
                          slidesToScroll: 1,
                          slidesToShow: 1,
                          loop: true,
                    });
                </script>
        </section>

        <section id="generations_captions">
          <h2 class="task-vis-title">üîç 3D scene generations and captions</h2>
                <p>
                    Given a reference image, we randomly sample plausible relative view transformations and let UniUGG generate the corresponding 3D scenes, and further caption the generated 3D scenes.
                </p>
          <section class="section-seed" style="overflow:hidden;">
              <!-- <div class="container"> -->
                  <div id="post_images" class="carousel">
                      <section class="three-column-layout">
                          <!-- Left: Reference Image -->
                          <div class="column reference-image">
                            <div class="section-title-reference">Reference image</div>
                            <img src="./models/meshseed4.png" alt="Reference Image">
                          </div>

                          <!-- Middle: Mesh Visualizations -->
                          <div class="column">
                            <div class="section-title">Random seed 1</div>
                            <div class="mesh-box" id="meshseed1_1"></div>

                            <div class="section-title">Random seed 2</div>
                            <div class="mesh-box" id="meshseed1_2"></div>
                          </div>

                          <!-- Right: Captions -->
                          <div class="column">
                            <div class="section-title">Caption</div>
                            <div class="caption-box">
                              A kitchen countertop with a double sink and a faucet, featuring a dish rack with dishes and a container to the right. A kettle sits on the counter to the left, with a window above the sink allowing natural light to enter.
                            </div>

                            <div class="section-title">Caption</div>
                            <div class="caption-box">
                              A kitchen sink area with a dish rack on the right holding a plate of food. To the left, there are cabinets and a countertop with items near the window.
                            </div>
                          </div>
                        </section>
                      <section class="three-column-layout">
                          <!-- Left: Reference Image -->
                          <div class="column reference-image">
                            <div class="section-title-reference">Reference image</div>
                            <img src="./models/meshseed0.png" alt="Reference Image">
                          </div>

                          <!-- Middle: Mesh Visualizations -->
                          <div class="column">
                            <div class="section-title">Random seed 1</div>
                            <div class="mesh-box" id="meshseed2_1"></div>

                            <div class="section-title">Random seed 2</div>
                            <div class="mesh-box" id="meshseed2_2"></div>
                          </div>

                          <!-- Right: Captions -->
                          <div class="column">
                            <div class="section-title">Caption</div>
                            <div class="caption-box">
                              A neatly made bed with white linens and a gray headboard is centered against a gray upholstered headboard. Above the bed, a framed artwork hang on the wall, and a small bedside table with a lamp is visible to the right.
                            </div>

                            <div class="section-title">Caption</div>
                            <div class="caption-box">
                              A neatly made bed with white linens and pillows are positioned against a wall, with a gray upholstered headboard. Above the bed, a framed artwork hang on the wall, and a small bedside table with a lamp is visible to the right.
                            </div>
                          </div>
                        </section>
                      <!-- <section class="three-column-layout">
                          <div class="column reference-image">
                            <div class="section-title-reference">Reference image</div>
                            <img src="./models/meshseed1.png" alt="Reference Image">
                          </div>

                          <div class="column">
                            <div class="section-title">Random seed 1</div>
                            <div class="mesh-box" id="meshseed3_1"></div>

                            <div class="section-title">Random seed 2</div>
                            <div class="mesh-box" id="meshseed3_2"></div>
                          </div>

                          <div class="column">
                            <div class="section-title">Caption</div>
                            <div class="caption-box">
                              A brown leather couch is positioned to the left, with a yellow lamp on a metal stand to the right, casting a shadow on a patterned wall. 
                            </div>

                            <div class="section-title">Caption</div>
                            <div class="caption-box">
                              A brown leather sofa with a purple cushion is positioned to the left, while a red lamp with a base stands on a wooden floor to the right. To the right, there is another purple sofa partially visible.
                            </div>
                          </div>
                        </section> -->
                  </div>
              <!-- </div> -->
        <script src="https://cdn.jsdelivr.net/npm/bulma-carousel@4.0.3/dist/js/bulma-carousel.min.js"></script>
                <script>
                    bulmaCarousel.attach('#post_images', {
                          slidesToScroll: 1,
                          slidesToShow: 1,
                          loop: true,
                    });
                </script>
          </section>
          <section class="spatial_understanding" id="spatial_understanding">
            <h2 class="task-vis-title">üí¨ Spatial understanding </h2>
                      <p> UniUGG can capture fine-grained spatial relations and support spatial visual question answering (VQA) tasks.</p>
                <section class="section-seed" style="overflow:hidden;">
                        <div id="post_images" class="carousel">
                                <div class="grid_comp">
                                  <section class="qa_section">
                                    <!-- ÂõæÁâáÂå∫Âüü -->
                                      <div class="video_grid_qa">
                                        <video controls>
                                        <source src="models/Q1.mp4" type="video/mp4">
                                        </video>
                                      </div>

                                    <!-- ÊñáÊú¨Âå∫Âüü -->
                                    <div class="text_block_qa">
                                      <div class="question_qa">
                                        <strong>üë§ Question:</strong>
                                        <p>
                                          These are frames of a video. How many ceiling light(s) are in this room?
                                        </p>
                                      </div>
                                      <div class="answer_qa">
                                        <strong>ü§ñ Answer:</strong>
                                        <p>
                                          The video reveals a total of 2 ceiling light occupying the room.
                                        </p>
                                      </div>
                                    </div>
                                  </section>
                                  </div>
                                  <div class="grid_comp">
                                    <section class="qa_section">
                                    <!-- ÂõæÁâáÂå∫Âüü -->
                                    <div class="image_grid_qa">
                                      <img src="models/Q2_1.png" alt="Image 1">
                                      <img src="models/Q2_2.png" alt="Image 2">
                                      <img src="models/Q2_3.png" alt="Image 3">
                                    </div>

                                    <!-- ÊñáÊú¨Âå∫Âüü -->
                                    <div class="text_block_qa">
                                      <div class="question_qa">
                                        <strong>üë§ Question:</strong>
                                        <p>
                                          In the given three images, what is the spatial alignment of the shoe 
                                          <span class="red_qa">(red bbox)</span> relative to the plant pot 
                                          <span class="blue_qa">(blue bbox)</span> as perceived by the observer? 
                                          Set the first image as the observer‚Äôs perspective.
                                        </p>
                                      </div>
                                      <div class="answer_qa">
                                        <strong>ü§ñ Answer:</strong>
                                        <p>
                                          In this arrangement, the shoe <span class="red_qa">(red bbox)</span> is positioned to the left below the 
                                          plant pot <span class="blue_qa">(blue bbox)</span>. From the observer‚Äôs perspective, it looks farther. 
                                          The shoe <span class="red_qa">(red bbox)</span> and the plant pot <span class="blue_qa">(blue bbox)</span> are in front 
                                          of the observer.
                                        </p>
                                      </div>
                                    </div>
                                  </section>
                                  </div>
                                  <div class="grid_comp">
                                  <section class="qa_section">
                                    <!-- ÂõæÁâáÂå∫Âüü -->
                                    <div class="image_grid_qa">
                                      <img src="models/Q3_1.png" alt="Image 1">
                                      <img src="models/Q3_2.png" alt="Image 2">
                                    </div>

                                    <!-- ÊñáÊú¨Âå∫Âüü -->
                                    <div class="text_block_qa">
                                      <div class="question_qa">
                                        <strong>üë§ Question:</strong>
                                        <p>
                                          The images are frames from a video. The video is shooting a static scene. The camera is either moving clockwise (left) or counter-clockwise (right) around the object. 
                                          The first image is from the beginning of the video and the second image is from the end. Is the camera moving left or right when shooting the video?
                                        </p>
                                      </div>
                                      <div class="answer_qa">
                                        <strong>ü§ñ Answer:</strong>
                                        <p>
                                          From the observer's perspective, the camera transitions left.
                                        </p>
                                      </div>
                                    </div>
                                  </section>
                                  </div>

                                  <div class="grid_comp">
                                  <section class="qa_section">
                                    <!-- ÂõæÁâáÂå∫Âüü -->
                                    <div class="single_image_grid_qa">
                                      <img src="models/Q4.png" alt="Image 1">
                                    </div>

                                    <!-- ÊñáÊú¨Âå∫Âüü -->
                                    <div class="text_block_qa">
                                      <div class="question_qa">
                                        <strong>üë§ Question:</strong>
                                        <p>
                                          Consider the real-world 3D locations of the objects. Which object has a lower location? 
                                          <br>A: fan<br>
                                          B: people 
                                        </p>
                                      </div>
                                      <div class="answer_qa">
                                        <strong>ü§ñ Answer:</strong>
                                        <p>
                                          The answer is A. The object fan is located at a lower height in the real world.
                                        </p>
                                      </div>
                                    </div>
                                  </section>
                                  </div>
                        
                        </div>
              <script src="https://cdn.jsdelivr.net/npm/bulma-carousel@4.0.3/dist/js/bulma-carousel.min.js"></script>
                      <script>
                          bulmaCarousel.attach('#post_images', {
                                slidesToScroll: 1,
                                slidesToShow: 1,
                                loop: true,
                          });
                      </script>
            </section>

            </div>

            <div class="main-content-exp">

            <section class="task-comparison-section", id="exp">
            <h2 class="section-title">üéØEvaluation on spatial understanding and 3D generation</h2>
          
            <div class="comparison-grid">
              <!-- QA Evaluation Block -->
              <div class="comparison-card">
                <h3>üí¨ Spatial understanding</h3>
                <p class="small-caption">3D understanding performance on various spatial reasoning benchmarks.</p>
              <table class="benchmark-table">
                <thead>
                  <tr>
                    <th rowspan="2"style="text-align: center; vertical-align: middle;">Method</th>
                    <th rowspan="2"style="text-align: center; vertical-align: middle;">VSI</th>
                    <th rowspan="2"style="text-align: center; vertical-align: middle;">BLINK</th>
                    <th rowspan="2"style="text-align: center; vertical-align: middle;">3DSR</th>
                    <th colspan="4">SPAR</th>
                  </tr>
                  <tr>
                    <td>Low</td>
                    <td>Med.</td>
                    <td>High</td>
                    <td>Avg.</td>
                  </tr>
                </thead>
                <tbody>
                  <tr class="group-label"><td colspan="5">üìÇ Open-source models</td></tr>
                  <tr>
                    <td style="text-align: left; white-space: nowrap;">LLaVA-v1.5-7B</td>
                    <td>18.0</td>
                    <td>37.1</td>
                    <td>38.1</td>
                    <td>10.9</td>
                    <td>26.5</td>
                    <td>34.1</td>
                    <td>23.7</td>
                  </tr>
                  <tr>
                    <td style="text-align: left; white-space: nowrap;">LLaVA-NeXT-7B</td>
                    <td>20.6</td>
                    <td>41.8</td>
                    <td>48.4</td>
                    <td>8.5</td>
                    <td>4.8</td>
                    <td>20.2</td>
                    <td>13.2</td>
                  </tr>
                  <tr>
                    <td style="text-align: left; white-space: nowrap;">InternVL2.5-8B</td>
                    <td>32.5</td>
                    <td>54.8</td>
                    <td>50.9</td>
                    <td>29.5</td>
                    <td><span style="text-decoration: underline;">31.9</span></td>
                    <td><span style="text-decoration: underline;">43.8</span></td>
                    <td>36.3</td>
                  </tr>
                  <tr>
                    <td style="text-align: left; white-space: nowrap;">Qwen2.5-VL-7B</td>
                    <td>30.3</td>
                    <td><span style="text-decoration: underline;">56.4</span></td>
                    <td>48.4</td>
                    <td>28.8</td>
                    <td>23.0</td>
                    <td>40.3</td>
                    <td>33.1</td>
                  </tr>
                  <tr class="group-label"><td colspan="5">‚òÅÔ∏è API models</td></tr>
                  <tr>
                    <td style="text-align: left; white-space: nowrap;">GPT-4o</td>
                    <td><span style="text-decoration: underline;">34.0</span></td>
                    <td><b>60.0</b></td>
                    <td>44.2</td>
                    <td><span style="text-decoration: underline;">36.9</span></td>
                    <td>26.5</td>
                    <td><span style="text-decoration: underline;">43.8</span></td>
                    <td><span style="text-decoration: underline;">38.1</span></td>
                  </tr>
                  <tr class="group-label"><td colspan="5">üîÑ Unified understanding-generation models</td></tr>
                  <tr>
                    <td style="text-align: left; white-space: nowrap;">Janus-Pro-1B</td>
                    <td>-</td>
                    <td>38.9</td>
                    <td>50.0</td>
                    <td>10.7</td>
                    <td>24.7</td>
                    <td>30.8</td>
                    <td>20.6</td>
                  </tr>
                  <tr>
                    <td style="text-align: left; white-space: nowrap;">Janus-Pro-7B</td>
                    <td>-</td>
                    <td>40.5</td>
                    <td><b>53.7</b></td>
                    <td>27.3</td>
                    <td>24.6</td>
                    <td>33.9</td>
                    <td>28.6</td>
                  </tr>
                  <tr>
                    <td style="text-align: left; white-space: nowrap;"><i>UniUGG-3B (Ours)</i></td>
                    <td><b>40.1</b></td>
                    <td>43.6</td>
                    <td><span style="text-decoration: underline;">52.1</span></td>
                    <td><b>50.8</b></td>
                    <td><b>41.7</b></td>
                    <td><b>45.7</b></td>
                    <td><b>47.2</b></td>
                  </tr>
                </tbody>
              </table>

              </div>
          
              <!-- Grounding Evaluation Block -->
              <div class="comparison-card">
                <h3>üì¶ 3D generation</h3>
                <p class="small-caption">Quantitative spatial generation comparison on ARKitScenes and ScanNet++ datasets.</p>
                <table class="benchmark-table">
                <thead>
                  <tr>
                    <th rowspan="2" style="text-align: center; vertical-align: middle;">Method</th>
                    <th colspan="3" style="text-align: center; vertical-align: middle;">ARKitScenes</th>
                    <th colspan="3" style="text-align: center; vertical-align: middle;">ScanNet++</th>
                  </tr>
                  <tr>
                    <th>FID‚Üì</th> 
                    <th>KID‚Üì</th>
                    <th>LPIPS‚Üì</th>
                    <th>FID‚Üì</th>
                    <th>KID‚Üì</th>
                    <th>LPIPS‚Üì</th>
                  </tr>
                </thead>
                <tbody>
                   <tr class="group-label"><td colspan="5">üß™ Ablation setting</td></tr>
                  <tr>
                    <td style="text-align: left; white-space: nowrap;">w/ RADIO</td>
                    <td><span style="text-decoration: underline;">64.16</span></td>
                    <td><span style="text-decoration: underline;">.0518</span></td>
                    <td> .4904 </td>
                    <td><span style="text-decoration: underline;">73.69</span></td>
                    <td><span style="text-decoration: underline;">.0614</span></td>
                    <td> .4629 </td>
                  </tr>
                  <tr>
                    <td style="text-align: left; white-space: nowrap;">w/ MASt3R Enc.</td>
                    <td>81.18</td>
                    <td>.0691</td>
                    <td>.5076</td>
                    <td>86.79</td>
                    <td>.0803</td>
                    <td>.5242</td>
                  </tr>
                  <tr>
                    <td style="text-align: left; white-space: nowrap;">w/o Dec. finetune</td>
                    <td>149.97</td>
                    <td>.1447</td>
                    <td>.5301</td>
                    <td>168.05</td>
                    <td>.1686</td>
                    <td>.4945</td>
                  </tr>
                  <tr>
                    <td style="text-align: left; white-space: nowrap;">w/o Diff.</td>
                    <td>87.51</td>
                    <td>.0672</td>
                    <td><b>.4494</b></td>
                    <td>114.93</td>
                    <td>.0955</td>
                    <td><span style="text-decoration: underline;">.4345</span></td>
                  </tr>
                  <tr class="group-label"><td colspan="5">üìè Baselins</td></tr>
                  <tr>
                    <td style="text-align: left; white-space: nowrap;">CUT3R</td>
                    <td>138.54</td>
                    <td>.1128</td>
                    <td>.5758</td>
                    <td>130.76</td>
                    <td>.1051</td>
                    <td>.5637</td>
                  </tr>
                  <tr>
                    <td style="text-align: left; white-space: nowrap;">LVSM</td>
                    <td>269.45</td>
                    <td>.3088</td>
                    <td>.5067</td>
                    <td>414.63</td>
                    <td>.5117</td>
                    <td>.5865</td>
                  </tr>
                  <tr>
                    <td style="text-align: left; white-space: nowrap;"><i>UniUGG (Ours)</i></td>
                    <td><b>55.01</b></td>
                    <td><b>.0425</b></td>
                    <td><span style="text-decoration: underline;">.4849</span></td>
                    <td><b>55.64</b></td>
                    <td><b>.0442</b></td>
                    <td><b>.4263</b></td>
                  </tr>
                </tbody>
              </table>
              </div>

            </div>
          </section>
      </div>
      
      <div class="main-content">
          
      <section class="method-section", id="method">
      <h2 class="task-vis-title">‚öôÔ∏è Method overview</h2>
      <section class="dataset-distribution-row-top">
        <div class="dist-img">
          <img src="assets/images/encoder.png" alt="Vision encoder pretraining">
        </div>
        <div class="dist-caption">
          <h3>üü¶ Vision encoder pretraining</h3>
          <p>
            <em>
              We introduce a novel geometric-semantic vision encoder pretraining strategy.
              <br>
              <strong>(a)</strong> During semantic guiding, our student encoder learns to mimic the teacher's visual representations.
              <br>
              <strong>(b)</strong> In spatial representation learning, the spatial decoder jointly refines predictions using information from both views.            </em>
          </p>
        </div>
      </section>    

      <section class="task-vis-section", id="vis">
        <img src="assets/images/training.png" alt="Spatial understanding and generation training" class="task-vis-img">
        <div style="text-align: left;">
        <h3>üü® Spatial understanding and generation training</h3>
        <p>
          <em>
            <strong>(a)</strong> In the latent token learning stage, visual representation is compressed using the Spatial-VAE, while the spatial decoder is linked for fine-tuning.
            <br>
            <strong>(b)</strong> In the unified learning stage, the reference image‚Äôs visual representation and view transformation are input to an LLM, which outputs conditional features for noise prediction on latent token. The LLM also performs VQA-related training to maintain its understanding capability.
          </em>
        </p>
        </div>
      </section>

      <section class="dataset-distribution-row">
        <div class="dist-img">
          <img src="assets/images/inference.png" alt="Task Distribution">
        </div>
        <div class="dist-caption">
          <h3>üü• Spatial understanding and generation inferencing</h3>
          <p>
            <em>
              <strong>(a)</strong> We achieve 3D generation by generating the target-view‚Äôs visual representation using the LLM and diffusion model. 
              <br>
              <strong>(b)</strong> The LLM performs VQA using visual representations as input, whether generated or real. 
              <br>
              <strong>(c)</strong> The visual representations of both target and reference views are input to the pretrained spatial decoder to decode 3D scene.
            </em>
          </p>
        </div>
      </section> 
      </section>   
        
          <section class="citation-section", id="citation">
            <h2 class="section-title">üìö Bibtex</h2>
          
            <p>If you find our work helpful, please consider citing us:</p>
          
            <pre><code>@article{xu2025uniugg,
title={UniUGG: Unified 3D Understanding and Generation via Geometric-Semantic Encoding},
author={Xu, Yueming and Zhang, Jiahui and Huang, Ze and Chen, Yurui and Zhou, Yanpeng and Chen Zhenyu and Yuan, Yujie and Xia, Pengxiang and Huang, Guowei and Cai, Xinyue and Qi, Zhongang and Quan, Xingyue and Hao, Jianye and Xu, Hang and Zhang, Li},
year={2025},
journal={arXiv preprint arXiv:2508.11952},
}</code></pre>
          </section>


        <!-- Floating TOC Button -->
        <div class="floating-toc" onclick="toggleTocPopup()">üìú Sections</div>

        <!-- Floating TOC Popup -->
        <div class="toc-popup" id="tocPopup">
        <a href="#overview">üìå Paper overview</a>
        <a href="#vis_gen">üåê Generation visualization</a>
        <a href="#paper-summary">üìÑ Abstract</a>
        <a href="#video">üéûÔ∏è Video</a>
        <a href="#generation_comparison">‚öñÔ∏è 3D generation comparison</a>
        <a href="#generations_captions">üîç 3D scene generations and captions</a>
        <a href="#spatial_understanding">üí¨ Spatial understanding</a>
        <a href="#exp">üéØ Evaluation</a>
        <a href="#method">‚öôÔ∏è Method overview</a>
        <a href="#citation">üìö Citation</a>
        </div>
        <script>
            function toggleTocPopup() {
              const toc = document.getElementById("tocPopup");
              toc.style.display = (toc.style.display === "block") ? "none" : "block";
            }
          
            // ÂèØÈÄâÔºöÁÇπÂáªÂÖ∂‰ªñÂå∫ÂüüÊó∂ÂÖ≥Èó≠ popup
            document.addEventListener('click', function (e) {
              const btn = document.querySelector('.floating-toc');
              const popup = document.getElementById('tocPopup');
              if (!btn.contains(e.target) && !popup.contains(e.target)) {
                popup.style.display = "none";
              }
            });
            
        </script>
        </div>
</body>

<script async src="https://unpkg.com/es-module-shims@1.3.6/dist/es-module-shims.js"></script>

    <script type="importmap">
        {
            "imports": {
                "three": "./js/three.module.js"
            }
        }
    </script>
    
    <script type="module">
    import * as THREE from './three.module.js';
    import { PLYLoader } from './PLYLoader.js'; // ‰πüÂèØ‰ª•Êç¢Êàê‰Ω†‰πãÂâçÈÇ£‰ªΩ PLYPointCloudLoader

    // Âú∫ÊôØ
    const scene = new THREE.Scene();
    scene.background = new THREE.Color(0x000000);

    // Áõ∏Êú∫
    const camera = new THREE.PerspectiveCamera(75, window.innerWidth / window.innerHeight, 0.01, 1000);
    camera.position.z = 2;

    // Ê∏≤ÊüìÂô®
    const renderer = new THREE.WebGLRenderer({ antialias: true });
    renderer.setSize(window.innerWidth, window.innerHeight);
    document.body.appendChild(renderer.domElement);

    // ËΩ®ÈÅìÊéßÂà∂Âô®ÔºàÂèØÈÄâÔºâ
    import { OrbitControls } from 'https://threejs.org/examples/jsm/controls/OrbitControls.js';
    const controls = new OrbitControls(camera, renderer.domElement);

    // ÁÇπ‰∫ëÊùêË¥®
    const pointMaterial = new THREE.PointsMaterial({
      size: 0.05,
      vertexColors: true
    });

    // Âä†ËΩΩPLYÁÇπ‰∫ë
    const loader = new PLYLoader();
    loader.load('model.ply', geometry => {
      geometry.computeVertexNormals(); // ÂèØÈÄâ
      const points = new THREE.Points(geometry, pointMaterial);
      scene.add(points);
    });

    // Ê∏≤ÊüìÂæ™ÁéØ
    function animate() {
      requestAnimationFrame(animate);
      controls.update();
      renderer.render(scene, camera);
    }

    animate();

    // ÂìçÂ∫îÁ™óÂè£ÂèòÂåñ
    window.addEventListener('resize', () => {
      camera.aspect = window.innerWidth / window.innerHeight;
      camera.updateProjectionMatrix();
      renderer.setSize(window.innerWidth, window.innerHeight);
    });
  </script>


    <script type="module">
        import * as THREE from 'three';

    import { PLYLoader } from './js/PLYLoader.js';
    import { OrbitControls } from './js/OrbitControls.js'
    let div_to_scene = {
        "sample_case1": {
            "geo": null,
            "color": null,
        },
        "sample_case2": {
            "geo": null,
            "color": null,
        },
        "sample_case3": {
            "geo": null,
            "color": null,
        },
        "sample_case4": {
            "geo": null,
            "color": null,
        },
        "sample_case5": {
            "geo": null,
            "color": null,
        },

        "meshseed1_1": {
            "geo": null,
            "color": null,
        },
        "meshseed1_2": {
            "geo": null,
            "color": null,
        }
    }
    let div_to_render_scene = {
        "mesh_style_0": {
            "0": null,
            "1": null,
            "2": null,
            "geo": null,
        },
        "mesh_style_1": {
            "0": null,
            "1": null,
            "2": null,
            "geo": null,
        },
        "mesh_style_2": {
            "0": null,
            "1": null,
            "2": null,
            "geo": null,
        },
        "mesh_style_3": {
            "0": null,
            "1": null,
            "2": null,
            "geo": null,
        },
    }
    let mouse_button_down = false;
    let list_of_orbit_controls = []
    let list_of_camera_init = []
    let style_camera = null;
    let render_colors = true;
    let style_id = "0"

    function setup_camera(div_name){
        // let container = document.getElementById(div_name);
        // let width = container.parentElement.clientWidth;
        // let height = container.parentElement.clientHeight;
        let width, height;
        let container = document.getElementById(div_name);
        if (div_name.includes("sample")) {
          width = container.parentElement.clientWidth;
          height = container.parentElement.clientHeight;
        } else {
          width = container.clientWidth;
          height = container.clientHeight;
        }
      
        let camera = new THREE.PerspectiveCamera( 35, width / height, 0.1, 50 );

        let camera_init_position = new THREE.Vector3( 2.25, 1.525, -3.75 );
        camera_init_position = camera_init_position.multiplyScalar(0.55)
        camera.position.set(camera_init_position.x, camera_init_position.y, camera_init_position.z);
        return camera;
    }

    function setup_render_divs(div_name, mesh_path){
        let camera = setup_camera(div_name)
        let orbit_control = create_render_div(camera, div_name, mesh_path)

        // orbit_control.saveState();
        list_of_orbit_controls.push(orbit_control)
        // list_of_camera_init.push(camera_init)
    }

    function create_render_div(camera, div_id, ply_path) {
    let container;
    let renderer, controls;

    init();
    animate();

    function init() {
        let width, height;
        container = document.getElementById(div_id);
        if (div_id.includes("sample")) {
          width = container.parentElement.clientWidth;
          height = container.parentElement.clientHeight;
        } else {
          width = container.clientWidth;
          height = container.clientHeight;
        }
      

        div_to_scene[div_id] = {
            "pointcloud": new THREE.Scene()
        };
        div_to_scene[div_id]["pointcloud"].background = new THREE.Color(0xffffff);

        // Âä†ËΩΩ PLY ÁÇπ‰∫ëÊñá‰ª∂
        const loader = new PLYLoader();
        loader.load(ply_path, function (geometry) {
            geometry.computeBoundingBox();

            const center = new THREE.Vector3();
            geometry.boundingBox.getCenter(center);
            geometry.translate(-center.x, -center.y, -center.z);

            const size = new THREE.Vector3();
            geometry.boundingBox.getSize(size);
            const maxDim = Math.max(size.x, size.y, size.z);
            const cameraDistance = maxDim * 1.2;

            // camera.position.set(-cameraDistance, cameraDistance, -cameraDistance);
            // camera.lookAt(0, 0, 0);

            if (div_id == "sample_case1") {
            geometry.translate(-0.2,0.2,0);
            camera.position.set(1.6230225350342913, -0.6234737139583433, -10.580383072470458);
            camera.lookAt(0.11114839239697578, -0.2644762011750067, 0.02392370737928461);
            }
            else if (div_id == "sample_case2") {
            geometry.translate(-1.15,-1.1,0);
            camera.position.set(0.9754964219328183, 2.517406240143193, -12.204394752459265);
            camera.lookAt(-0.13833566556182408, 0.4339470960846704, 0.0614466252405209);
            } 
            else if (div_id == "sample_case3") {
            geometry.translate(1.0,0.8,0);
            camera.position.set(0.0787889354865618, -1.7679012697541576, -11.30418255421156);
            camera.lookAt(0.30173379710215437, 0.1990478654557605, -0.040776980350966684);
            } 
            else if (div_id == "sample_case4") {
            geometry.translate(-0.5,-0.2,0);
            camera.position.set(-0.7032851032269549, 1.5349932868720284, -9.212814739904227);
            camera.lookAt(0.27758942337233355, 0.23186805929506343, -0.020830662725487767);
            } 
            else if (div_id == "sample_case5") {
                geometry.translate(2.1,1.6,0);
                camera.position.set(0.1414997446191119, -4.184683563023461, -18.816445494560966);
                camera.lookAt(0,0,0);
            }
            else if (div_id == "meshseed1_1") {
                geometry.translate(0,0.6,0);
                camera.position.set(1.0030601064612272, -0.1088538358867176, -14.13416233754261);
                camera.lookAt(0.2514249565446477, 0.21558620250131819, 0.00935426841167492);
            }
            else if (div_id == "meshseed1_2") {
                geometry.translate(0,0.6,0);
                camera.position.set(1.0030601064612272, -0.1088538358867176, -14.13416233754261);
                camera.lookAt(0.2514249565446477, 0.21558620250131819, 0.00935426841167492);
            }
            else if (div_id == "meshseed2_1") {
                geometry.translate(-0.7,0,0);
                camera.position.set(1.5441232684641364, -6.611089234298225, -17.0395607415357);
                camera.lookAt(0,0,0);
            }
            else if (div_id == "meshseed2_2") {
                geometry.translate(-0.7,0,0);
                camera.position.set(0.14149974461911177, -4.184683563023455, -18.816445494560945);
                camera.lookAt(0,0,0);
            }
            // else if (div_id == "meshseed3_1") {
            //     geometry.translate(3.0,0.8,0);
            //     camera.position.set(1.8009893785847924, -7.710849085054061, -19.874104961697856);
            //     camera.lookAt(0,0,0);
            // }
            // else if (div_id == "meshseed3_2") {
            //     geometry.translate(2.5,1.0,0);
            //     camera.position.set(0.17372456579567302, -5.137693618708831, -23.101658820372418);
            //     camera.lookAt(0,0,0);
            // }
            else if (div_id == "meshcomp_ours1") {
                geometry.translate(0,-0.2,0);
                camera.position.set(-0.6029351653858079, 2.409739498603034, -11.243305433879831);
                camera.lookAt(0.2605144437816586, 0.5251704276204188, 0.06761420596854788);
            }
            else if (div_id == "meshcomp_cut3r1") {
                camera.position.set(-0.1588855317391846, 0.6350147803096983, -2.9628369100431895);
                camera.lookAt(0,0,0);
            }
            else if (div_id == "meshcomp_ours2") {
                geometry.translate(1.5,0,0);
                camera.position.set(0.1509333906542638, 1.0095877890502678, -14.621696423829443);
                camera.lookAt(-2.2359452116612033, 0.012120463725496142, 0.30967244334301236);
              }
            else if (div_id == "meshcomp_cut3r2") {
                geometry.translate(0.7,0,0);
                camera.position.set(-0.10204247789220514, 0.7373891237088912, -3.643367950197162);
                camera.lookAt(-0.24401574038757337, -0.0315091379023128, 0.002179183646267757);
            }
            else if (div_id == "meshcomp_ours3") {
                geometry.translate(3.8,0.2,0);
                camera.position.set(-10.707202397720406, 4.939583621126656, -9.619093725704547);
                camera.lookAt(-0.7835858651885019, 0.030434162586977648, 0.7633625743797616);
              }
            else if (div_id == "meshcomp_cut3r3") {
                geometry.translate(1.0,0.1,0);
                camera.position.set(-4.247510970569815, 1.3082676737398056, -2.990237367827976);
                camera.lookAt(-0.3853986462949379, -0.18438584278501854, 0.36071567888471245);
            }

            // ÁÇπ‰∫ëÊùêË¥®
            const material = new THREE.PointsMaterial({
                size: 0.2,
                vertexColors: geometry.hasAttribute('color'),
                // color: 0x5588ff // Â¶ÇÊûúÊ≤°ÊúâÈ¢úËâ≤Â±ûÊÄßÔºå‰ΩøÁî®ÈªòËÆ§È¢úËâ≤
            });

            const points = new THREE.Points(geometry, material);
            div_to_scene[div_id]["pointcloud"].add(points);
            div_to_scene[div_id]["old_points"] = points
            div_to_scene[div_id]["camera"] = camera
            div_to_scene[div_id]["controls"] = controls

            // Ê∑ªÂä†ÁõëÂê¨Âô®
            controls.addEventListener('change', () => {
                console.log('Camera position:', camera.position.toArray());
                console.log('Camera lookAt (target):', controls.target.toArray());
            });
        },
            (xhr) => {
                console.log((xhr.loaded / xhr.total * 100) + '% loaded');
            },
            (error) => {
                console.error('PLY load error:', error);
            }
        );

        // ÁÅØÂÖâ
        const hemiLight = new THREE.HemisphereLight(0xffffff, 0x444444, 0.5);
        div_to_scene[div_id]["pointcloud"].add(hemiLight);

        // Ê∏≤ÊüìÂô®ËÆæÁΩÆ
        renderer = new THREE.WebGLRenderer({ antialias: true });
        renderer.setPixelRatio(window.devicePixelRatio);
        renderer.setSize(width, height);
        renderer.outputEncoding = THREE.sRGBEncoding;
        container.appendChild(renderer.domElement);

        // ÊéßÂà∂Âô®ËÆæÁΩÆ
        controls = new OrbitControls(camera, renderer.domElement);
        controls.enableDamping = true;
        controls.dampingFactor = 0.05;

        window.addEventListener('resize', onWindowResize);
    }

    function onWindowResize() {
        let width = container.parentElement.clientWidth;
        let height = container.parentElement.clientHeight;
        camera.aspect = width / height;
        camera.updateProjectionMatrix();
        renderer.setSize(width, height);
    }

    function animate() {
        requestAnimationFrame(animate);
        controls.update();
        renderer.render(div_to_scene[div_id]["pointcloud"], camera);
    }

    return controls
}

    function addShadowedLight(scene, x, y, z, color, intensity ) {

        const directionalLight = new THREE.DirectionalLight( color, intensity );
        directionalLight.position.set( x, y, z );
        scene.add( directionalLight );

        directionalLight.castShadow = true;

        const d = 1;
        directionalLight.shadow.camera.left = - d;
        directionalLight.shadow.camera.right = d;
        directionalLight.shadow.camera.top = d;
        directionalLight.shadow.camera.bottom = - d;

        directionalLight.shadow.camera.near = 1;
        directionalLight.shadow.camera.far = 4;

        directionalLight.shadow.mapSize.width = 1024;
        directionalLight.shadow.mapSize.height = 1024;

        directionalLight.shadow.bias = - 0.001;

    }

    document.addEventListener('keydown', logKey);

    function logKey(evt) {
        if (evt.keyCode === 71 && !mouse_button_down) {
            // switch_geometry()
            replace_pointcloud("sample_case1", './models/sample1_gen.ply', true)
            replace_pointcloud("sample_case2", './models/sample2_gen.ply', true)
            replace_pointcloud("sample_case3", './models/sample3_gen.ply', true)
            replace_pointcloud("sample_case4", './models/sample4_gen.ply', true)
            replace_pointcloud("sample_case5", './models/meshseed_1_2.ply', true)
        }
        if (evt.keyCode === 82 && !mouse_button_down) {

            replace_pointcloud("sample_case1", './models/sample1.ply')
            replace_pointcloud("sample_case2", './models/sample2.ply')
            replace_pointcloud("sample_case3", './models/sample3.ply')
            replace_pointcloud("sample_case4", './models/sample4.ply')
            replace_pointcloud("sample_case5", './models/sample5.ply')
        }
    }

    function switch_geometry() {
        render_colors = !render_colors
    }

    function replace_pointcloud(div_id, new_ply_path, gen = false) {
    // let camera = setup_camera(div_id)
    const scene = div_to_scene[div_id]["pointcloud"];
    const oldPoints = div_to_scene[div_id]["old_points"];
    const camera = div_to_scene[div_id]["camera"];
    const controls = div_to_scene[div_id]["controls"];

    if (oldPoints) {
        scene.remove(oldPoints);
        oldPoints.geometry.dispose();
        oldPoints.material.dispose();
    }

    const loader = new PLYLoader();
    loader.load(new_ply_path, function (geometry) {
        // geometry.computeBoundingBox();
        // geometry.center();
        geometry.computeBoundingBox();

        const center = new THREE.Vector3();
        geometry.boundingBox.getCenter(center);
        geometry.translate(-center.x, -center.y, -center.z);  

        const material = new THREE.PointsMaterial({
            size: 0.2,
            vertexColors: geometry.hasAttribute('color')
        });

        const newPoints = new THREE.Points(geometry, material);
        scene.add(newPoints);
        div_to_scene[div_id]["old_points"] = newPoints;

        // ‚úÖ ÈáçÊñ∞ËÆæÁΩÆËßÜËßí
        const size = new THREE.Vector3();
        geometry.boundingBox.getSize(size);
        const maxDim = Math.max(size.x, size.y, size.z);
        const cameraDistance = maxDim * 2.0;

        if (gen) {
          if (div_id == "sample_case1") {
            geometry.translate(0.25,0.25,0);
            camera.position.set(-0.33495542093006947, 0.5351001270264002, -15.344135222323422);
            camera.lookAt(-0.24414380491916332, -0.18998936067360706, -0.007512305468929134 );
          }
          else if (div_id == "sample_case2") {
            geometry.translate(-2.1,-0.2,0);
            camera.position.set(1.4146791736565425, 3.7352682016439167, -19.4888688194049);
            camera.lookAt(0,0,0);
            } 
          else if (div_id == "sample_case3") {
            geometry.translate(5.8,1.6,0);
            camera.position.set(-5.8417940622082565, -2.172554252972644, -20.78835510822863);
            camera.lookAt(0,0,0);
          }
          else if (div_id == "sample_case4") {
            geometry.translate(0,-0.5,0);
            camera.position.set(1.8356574680512194, 4.29455009496978, -12.631850506803769);
            camera.lookAt(0.2107390071914075, 0.6707376442203, 0.17890295060176492);
          }
          else if (div_id == "sample_case5") {
            geometry.translate(3.3,1.6,0);
            camera.position.set(3.63627548891057, -5.075209363770819, -20.426332478687243);
            camera.lookAt(0,0,0);
          }
        }
        else {
            if (div_id == "sample_case1") {
            geometry.translate(-0.2,0.2,0);
            camera.position.set(1.6230225350342913, -0.6234737139583433, -10.580383072470458);
            camera.lookAt(0.11114839239697578, -0.2644762011750067, 0.02392370737928461);
            } 
            else if (div_id == "sample_case2") {
            geometry.translate(-1.15,-1.1,0);
            camera.position.set(0.9754964219328183, 2.517406240143193, -12.204394752459265);
            camera.lookAt(-0.13833566556182408, 0.4339470960846704, 0.0614466252405209);
            } 
            else if (div_id == "sample_case3") {
            geometry.translate(1.0,0.8,0);
            camera.position.set(0.0787889354865618, -1.7679012697541576, -11.30418255421156);
            camera.lookAt(0.30173379710215437, 0.1990478654557605, -0.040776980350966684);
            } 
            else if (div_id == "sample_case4") {
            geometry.translate(-0.5,-0.2,0);
            camera.position.set(-0.7032851032269549, 1.5349932868720284, -9.212814739904227);
            camera.lookAt(0.27758942337233355, 0.23186805929506343, -0.020830662725487767);
            } 
            else if (div_id == "sample_case5") {
            geometry.translate(2.1,1.6,0);
            camera.position.set(0.1414997446191119, -4.184683563023461, -18.816445494560966);
            camera.lookAt(0,0,0);
            }
        }

        // controls.target.set(0, 0, 0);
        // controls.update();
    });
    }

    function reset_orbit_controls() {
        list_of_orbit_controls.forEach(oc => {
            oc.reset()
            // oc.update()
        })
    }

    function set_style_0(){
        style_id = "0"
    }

    function set_style_1(){
        style_id = "1"
    }

    function set_style_2(){
        style_id = "2"
    }

    document.body.onmousedown = function(evt) {
        if (evt.button === 0)
            mouse_button_down = true
    }
    document.body.onmouseup = function(evt) {
        if (evt.button === 0)
            mouse_button_down = false
    }

    window.onload = function() {
        let slider = document.getElementsByClassName("slider")[0]
        slider.removeAttribute("tabIndex")
        // slider.addEventListener("mouseout", reset_orbit_controls);
        
        setup_render_divs("sample_case1", './models/sample1.ply')
        setup_render_divs("sample_case2", './models/sample2.ply')
        setup_render_divs("sample_case3", './models/sample3.ply')
        setup_render_divs("sample_case4", './models/sample4.ply')
        setup_render_divs("sample_case5", './models/sample5.ply')

        setup_render_divs("meshcomp_ours1", './models/case1_ours.ply')
        setup_render_divs("meshcomp_cut3r1", './models/case1_cut.ply')
        setup_render_divs("meshcomp_ours2", './models/case2_ours.ply')
        setup_render_divs("meshcomp_cut3r2", './models/case2_cut.ply')
        setup_render_divs("meshcomp_ours3", './models/case3_ours.ply')
        setup_render_divs("meshcomp_cut3r3", './models/case3_cut.ply')

        setup_render_divs("meshseed1_1", './models/meshseed_4_1.ply')
        setup_render_divs("meshseed1_2", './models/meshseed_4_2.ply')
        setup_render_divs("meshseed2_1", './models/meshseed_0_1.ply')
        setup_render_divs("meshseed2_2", './models/meshseed_0_2.ply')

    };

    </script>

</html>
